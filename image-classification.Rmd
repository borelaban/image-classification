---
title: "CIFAR Image Classification"
author: "Laban Bore"
date: "4/8/2021"
output: html_document
---

```{r setup, include=TRUE}
knitr::opts_chunk$set(echo = TRUE)
library(tensorflow)
library(keras)

#install_tensorflow() installed this from github
#install_keras() installed this from github
```

## Download and prepare CIFAR dataset

The dataset consist of 60,000 colored images; 50,000 training and 10,000 testing grouped into 10 classes. They are mutually exclusive and no overlap.


```{r cifar-dataset}
cifar <- dataset_cifar10() #load the data and store in cifar
```

## Data verification

You can also embed plots, for example:

```{r cifar-plot}
class_names <- c('airplane', 'automobile', 'bird', 'cat', 'deer',
                 'dog', 'frog', 'horse', 'ship', 'truck')
index <- 1:30
#plot the first 25 images from the training set and display the class name below each image.
par(mfcol = c(5,6), mar = rep(1, 4), oma = rep(0.2, 4))
cifar$train$x[index,,,] %>% 
  purrr::array_tree(1) %>%
  purrr::set_names(class_names[cifar$train$y[index] + 1]) %>% 
  purrr::map(as.raster, max = 255) %>%
  purrr::iwalk(~{plot(.x); title(.y)})
```

# Create the convolutional base model
Create a stack of Conv2D and MaxPooling2D layers

```{r}
model <- keras_model_sequential() %>% 
  layer_conv_2d(filters = 32, kernel_size = c(3,3), activation = "relu", input_shape = c(32,32,3)) %>% 
  layer_max_pooling_2d(pool_size = c(2,2)) %>% 
  layer_conv_2d(filters = 64, kernel_size = c(3,3), activation = "relu") %>% 
  layer_max_pooling_2d(pool_size = c(2,2)) %>% 
  layer_conv_2d(filters = 64, kernel_size = c(3,3), activation = "relu")

```

## Model architecture

```{r}
summary(model)
```

The width and height dimensions tend to shrink as you go deeper in the network
Dense layers take vectors as input (which are 1D)
The current output is of 3D
Flatten the 3D to 1D then add one or more dense layer on top
Since CIFAR has 10 output classes we use the dense layer with 10 outputs and softmax activation

# Complete model architecture

```{r}
model %>% 
  layer_flatten() %>% 
  layer_dense(units = 64, activation = "relu") %>% 
  layer_dense(units = 10, activation = "softmax")
summary(model)
```

## compile and train the model

```{r}
model %>% compile(
  optimizer = "adam",
  loss = "sparse_categorical_crossentropy",
  metrics = "accuracy"
)

history <- model %>% 
  fit(
    x = cifar$train$x, y = cifar$train$y,
    epochs = 10,
    validation_data = unname(cifar$test),
    verbose = 2
  )
```

# Plot

```{r}
plot(history, col=TRUE)

#library(ggplot2)
#library(hrbrthemes)
# Plot
#ggplot(history) +
#  geom_line( color="#69b3a2", size=2, alpha=0.9, linetype=2) +
#  theme_ipsum() +
#  ggtitle("Evolution of something")

```

# Evaluate the model
```{r}
evaluate(model, cifar$test$x, cifar$test$y, verbose = 0)
```


